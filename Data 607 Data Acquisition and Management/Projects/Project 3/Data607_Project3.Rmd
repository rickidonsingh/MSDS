---
title: "Data607_Project 3"
author: "RSingh"
date: "3/24/2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r}
library(dplyr)
library(stringr)
library(tidyr)
library(ggplot2)
install.packages("tm")
library(tm)
library(wordcloud)
```


```{r}
#A. Read in the dataframe
#Read in raw dataframe, set separator as pipe
url <- "https://raw.githubusercontent.com/plb2018/DATA607/master/Project%203/indeed_jobs_large.csv"
df <- read.csv(url, sep="|", stringsAsFactors = F)
View(df)
```


```{r}
#Remove "location" and "salary" columns, to reduce redundancy.
df <- df[, -c(5,7)]
View(df)
```


```{r}
#Remove brackets surrounding summaries
df1 <- df %>% separate(summary_full, c("bracket", "new_summary"), sep="^[\\[]", remove=T, convert=F) %>%
    separate(new_summary, c("summary_full", "bracket"), sep="[\\]]$", remove=T, convert=F)
df1 <- df1[, -c(6, 7)]
View(df1)
```


```{r}
#Rename column headers
names(df1) <- c("list_ID", "city", "job_title", "company_name", "link", "summary")
View(df1)
```


```{r}
# Remove state and plus signs from city column
# Separate city column into city and state by pattern of two uppercase letters after a plus sign (i.e., "+NY")
df2 <- df1 %>% separate(city, c("city", "state"), sep="[\\+][[:upper:]][[:upper:]]$", convert=T)
# Remove empty State column
df2 <- df2[, -c(3)]
# Replace plus signs with spaces
df2$city <- str_replace_all(df2$city, "[\\+]", " ")
names(df2) <- c("list_ID", "city", "job_title", "company_name", "link", "summary")
df2 <- df2[, -c(7)]
View(df2)
```


```{r}
#Remove rows where Summary is blank
df_final <- filter(df2, df2$summary!="")
View(df_final)
```


Analysis assumptions: (Supervised Approach)
- We assumed certain terms fell into certain categories and searched for them. 
- We arrived at these categories / lists based on SMEs (Violeta sourcing)
- Assumed that the tools would lead to conclusions without human intervention.

Word Cloud
- Removed some stopwords, and in addition other words like “data” that wouldn’t add context


Analysis: 
To find which are the most valued data science skills using a Supervised approach- created new variables for analyzing three types of skills (Hard skills, Soft skills, and Tools)


```{r}
#Used mutate function to create new variables for Tool Skills and preserve existing ones; turned on case insensitivity

toolskills <- df_final %>%
    mutate(R = grepl("\\bR\\b,", summary)) %>%
    mutate(python = grepl("Python", summary, ignore.case=TRUE)) %>%
    mutate(SQL = grepl("SQL", summary, ignore.case=TRUE)) %>%
    mutate(hadoop = grepl("hadoop", summary, ignore.case=TRUE)) %>%
    mutate(perl = grepl("perl", summary, ignore.case=TRUE)) %>%
    mutate(matplotlib = grepl("matplotlib", summary, ignore.case=TRUE)) %>%
    mutate(Cplusplus = grepl("C++", summary, fixed=TRUE)) %>%
    mutate(VB = grepl("VB", summary, ignore.case=TRUE)) %>%
    mutate(java = grepl("java\\b", summary, ignore.case=TRUE)) %>%
    mutate(scala = grepl("scala", summary, ignore.case=TRUE)) %>%
    mutate(tensorflow = grepl("tensorflow", summary, ignore.case=TRUE)) %>%
    mutate(javascript = grepl("javascript", summary, ignore.case=TRUE)) %>%
    mutate(spark = grepl("spark", summary, ignore.case=TRUE)) %>%
    select(job_title, company_name, R, python, SQL, hadoop, perl, matplotlib, Cplusplus, VB, java, scala, tensorflow, javascript, spark)

#apply the summarise_all function to all (non-grouping) columns
toolskills2 <- toolskills %>% select(-(1:2)) %>% summarise_all(sum) %>% gather(variable,value) %>% arrange(desc(value))

#Let's visualize the most in demand Tool SKills
ggplot(toolskills2,aes(x=reorder(variable, value), y=value)) + geom_bar(stat='identity',fill="green") + xlab('') + ylab('Frequency') + labs(title='Tool Skills') + coord_flip() + theme_minimal()
```

For Tool Skills - Python, SQL, R are the top skills currently in demand and the least being VB. 


```{r}
#Used mutate function to create new variables for Soft Skills and preserve existing ones; turned on case insensitivity

softskills <- df_final %>%
    mutate(workingremote = grepl("working remote", summary, ignore.case=TRUE)) %>%
    mutate(communication = grepl("communicat", summary, ignore.case=TRUE)) %>%
    mutate(collaborative = grepl("collaborat", summary, ignore.case=TRUE)) %>%
    mutate(creative = grepl("creativ", summary, ignore.case=TRUE)) %>%
    mutate(critical = grepl("critical", summary, ignore.case=TRUE)) %>%
    mutate(problemsolving = grepl("problem solving", summary, ignore.case=TRUE)) %>%
    mutate(activelearning = grepl("active learning", summary, ignore.case=TRUE)) %>%
    mutate(hypothesis = grepl("hypothesis", summary, ignore.case=TRUE)) %>%
    mutate(organized = grepl("organize", summary, ignore.case=TRUE)) %>%
    mutate(judgement = grepl("judgement", summary, ignore.case=TRUE)) %>%
    mutate(selfstarter = grepl("self Starter", summary, ignore.case=TRUE)) %>%
    mutate(interpersonalskills = grepl("interpersonal skills", summary, ignore.case=TRUE)) %>%
    mutate(atttodetail = grepl("attention to detail", summary, ignore.case=TRUE)) %>%
    mutate(visualization = grepl("visualization", summary, ignore.case=TRUE)) %>%
    mutate(leadership = grepl("leadership", summary, ignore.case=TRUE)) %>%
    
select(job_title, company_name, workingremote, communication, collaborative, creative, critical, problemsolving, activelearning, hypothesis, organized, judgement, selfstarter, interpersonalskills, atttodetail, visualization, leadership)
summary(softskills) 

softskills2 <- softskills %>% select(-(1:2)) %>% summarise_all(sum) %>% gather(variable,value) %>% arrange(desc(value))

#Let's visualize the most in demand Soft SKills
ggplot(softskills2,aes(x=reorder(variable, value), y=value)) + geom_bar(stat='identity',fill="green") + xlab('') + ylab('Frequency') + labs(title='Soft Skills') + coord_flip() + theme_minimal()
```

Soft Skills- Communication, Collaboration, Visualization are the top skills currently in demand and the least being active learning.


```{r}
##Used mutate function to create new variables for Hard Skills and preserve existing ones; turned on case insensitivity

hardskills <- df_final %>%
    mutate(machinelearning = grepl("machine learning", summary, ignore.case=TRUE)) %>%
    mutate(modeling = grepl("model", summary, ignore.case=TRUE)) %>%
    mutate(statistics = grepl("statistics", summary, ignore.case=TRUE)) %>%
    mutate(programming = grepl("programming", summary, ignore.case=TRUE)) %>%
    mutate(quantitative = grepl("quantitative", summary, ignore.case=TRUE)) %>%
    mutate(debugging = grepl("debugging", summary, ignore.case=TRUE)) %>%
    mutate(statistics = grepl("statistics",  summary, ignore.case=TRUE)) %>%
    

select(job_title, company_name, machinelearning, modeling, statistics, programming, quantitative, debugging, statistics)
summary(hardskills) 


hardskills2 <- hardskills %>% select(-(1:2)) %>% summarise_all(sum) %>% gather(variable,value) %>% arrange(desc(value))

#Let's visualize the most in demand Hard SKills
ggplot(hardskills2,aes(x=reorder(variable, value), y=value)) + geom_bar(stat='identity',fill="green") + xlab('') + ylab('Frequency') + labs(title='Hard Skills') + coord_flip() + theme_minimal()
```

Hard Skills- Modeling and Machine Learning are the top skills currently in demand, and the least being debugging. 


Specified removal of irrelevant words and stopwords; the summary column was used to create the Data Science Skills word cloud.
```{r}
#Word Cloud
datacloud <- Corpus(VectorSource(df_final$summary))
datacloud <- tm_map(datacloud, removePunctuation)
datacloud <- tm_map(datacloud, tolower)
datacloud <- tm_map(datacloud, removeWords, c("services", "data", "andor", "ability", "using", "new", "science", "scientist" , "you", "must", "will", "including", "can", stopwords('english')))

#Let's visualize our data science word cloud
wordcloud(datacloud, max.words = 50, random.order = FALSE, scale=c(3,.3),random.color = FALSE,colors=palette())
```


